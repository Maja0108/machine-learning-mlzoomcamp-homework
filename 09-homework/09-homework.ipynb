{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1cca3ce",
   "metadata": {},
   "source": [
    "Check the downloaded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dea0cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output name: output\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "\n",
    "# Load the model\n",
    "onnx_model = onnx.load(\"./data/hair_classifier_v1.onnx\")\n",
    "\n",
    "# Print the names of all output nodes\n",
    "for output in onnx_model.graph.output:\n",
    "    print(f\"Output name: {output.name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a974fe8",
   "metadata": {},
   "source": [
    "Preparation of image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee34f054",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from urllib import request\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "def download_image(url):\n",
    "    with request.urlopen(url) as resp:\n",
    "        buffer = resp.read()\n",
    "    stream = BytesIO(buffer)\n",
    "    img = Image.open(stream)\n",
    "    return img\n",
    "\n",
    "\n",
    "def prepare_image(img, target_size):\n",
    "    if img.mode != 'RGB':\n",
    "        img = img.convert('RGB')\n",
    "    img = img.resize(target_size, Image.NEAREST)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "004ddc11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input name: input, Expected input shape: ['s77', 3, 200, 200]\n",
      "Model output (probability): [0.09156627]\n",
      "Predicted hair type: Straight\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "from PIL import Image\n",
    "from urllib import request\n",
    "from io import BytesIO\n",
    "\n",
    "# Function to download image from URL\n",
    "def download_image(url):\n",
    "    with request.urlopen(url) as resp:\n",
    "        buffer = resp.read()\n",
    "    stream = BytesIO(buffer)\n",
    "    img = Image.open(stream)\n",
    "    return img\n",
    "\n",
    "# Function to resize the image to target size (200x200)\n",
    "def prepare_image(img, target_size=(200, 200)):\n",
    "    if img.mode != 'RGB':\n",
    "        img = img.convert('RGB')\n",
    "    img = img.resize(target_size, Image.NEAREST)\n",
    "    return img\n",
    "\n",
    "# Preprocessing function (normalization)\n",
    "def preprocess_image(img):\n",
    "    # Convert to numpy array and normalize to [0, 1]\n",
    "    img_np = np.array(img).astype(np.float32) / 255.0  # Ensure the type is float32\n",
    "    \n",
    "    # Mean and standard deviation used for image normalization\n",
    "    mean = [0.485, 0.456, 0.406]\n",
    "    std = [0.229, 0.224, 0.225]\n",
    "    \n",
    "    # Normalize the image (subtract mean and divide by std)\n",
    "    img_np = (img_np - mean) / std\n",
    "    \n",
    "    # Ensure the type is float32 after all operations\n",
    "    img_np = img_np.astype(np.float32)\n",
    "    \n",
    "    # Reshape for the model input (adding batch dimension)\n",
    "    img_np = np.transpose(img_np, (2, 0, 1))  # Convert from HWC to CHW format\n",
    "    img_np = np.expand_dims(img_np, axis=0)  # Add batch dimension: (1, 3, 200, 200)\n",
    "    \n",
    "    return img_np\n",
    "\n",
    "# Function to load the ONNX model\n",
    "def load_model(model_path):\n",
    "    session = ort.InferenceSession(model_path)\n",
    "    return session\n",
    "\n",
    "# Function to run inference on the image\n",
    "def run_inference(session, img_np):\n",
    "    # Get input and output names\n",
    "    input_name = session.get_inputs()[0].name\n",
    "    output_name = session.get_outputs()[0].name\n",
    "    \n",
    "    # Ensure the input shape is as expected\n",
    "    print(f\"Input name: {input_name}, Expected input shape: {session.get_inputs()[0].shape}\")\n",
    "    \n",
    "    # Run inference\n",
    "    output = session.run([output_name], {input_name: img_np})\n",
    "    return output\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    # Step 1: Download the image from the URL\n",
    "    image_url = \"https://habrastorage.org/webt/yf/_d/ok/yf_dokzqy3vcritme8ggnzqlvwa.jpeg\"\n",
    "    img = download_image(image_url)\n",
    "    \n",
    "    # Step 2: Resize the image to 200x200\n",
    "    img_resized = prepare_image(img, target_size=(200, 200))\n",
    "    \n",
    "    # Step 3: Preprocess the image (normalize and reshape)\n",
    "    img_np = preprocess_image(img_resized)\n",
    "    \n",
    "    # Step 4: Load the ONNX model\n",
    "    model_path = \"./data/hair_classifier_v1.onnx\"  # Path to your ONNX model\n",
    "    session = load_model(model_path)\n",
    "    \n",
    "    # Step 5: Run inference on the image\n",
    "    output = run_inference(session, img_np)\n",
    "    \n",
    "    # Step 6: Display the output (probability)\n",
    "    print(f\"Model output (probability): {output[0][0]}\")\n",
    "    \n",
    "    # Optionally: If the model outputs a binary classification (0 = straight, 1 = curly)\n",
    "    prediction = \"Curly\" if output[0][0] > 0.5 else \"Straight\"\n",
    "    print(f\"Predicted hair type: {prediction}\")\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
